{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import  pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = pd.read_csv('Training.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>itching</th>\n",
       "      <th>skin_rash</th>\n",
       "      <th>nodal_skin_eruptions</th>\n",
       "      <th>continuous_sneezing</th>\n",
       "      <th>shivering</th>\n",
       "      <th>chills</th>\n",
       "      <th>joint_pain</th>\n",
       "      <th>stomach_pain</th>\n",
       "      <th>acidity</th>\n",
       "      <th>ulcers_on_tongue</th>\n",
       "      <th>...</th>\n",
       "      <th>blackheads</th>\n",
       "      <th>scurring</th>\n",
       "      <th>skin_peeling</th>\n",
       "      <th>silver_like_dusting</th>\n",
       "      <th>small_dents_in_nails</th>\n",
       "      <th>inflammatory_nails</th>\n",
       "      <th>blister</th>\n",
       "      <th>red_sore_around_nose</th>\n",
       "      <th>yellow_crust_ooze</th>\n",
       "      <th>prognosis</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>Fungal infection</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>Fungal infection</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>Fungal infection</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>Fungal infection</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>Fungal infection</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4915</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>(vertigo) Paroymsal  Positional Vertigo</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4916</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>Acne</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4917</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>Urinary tract infection</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4918</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>Psoriasis</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4919</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>Impetigo</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>4920 rows Ã— 133 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      itching  skin_rash  nodal_skin_eruptions  continuous_sneezing  \\\n",
       "0           1          1                     1                    0   \n",
       "1           0          1                     1                    0   \n",
       "2           1          0                     1                    0   \n",
       "3           1          1                     0                    0   \n",
       "4           1          1                     1                    0   \n",
       "...       ...        ...                   ...                  ...   \n",
       "4915        0          0                     0                    0   \n",
       "4916        0          1                     0                    0   \n",
       "4917        0          0                     0                    0   \n",
       "4918        0          1                     0                    0   \n",
       "4919        0          1                     0                    0   \n",
       "\n",
       "      shivering  chills  joint_pain  stomach_pain  acidity  ulcers_on_tongue  \\\n",
       "0             0       0           0             0        0                 0   \n",
       "1             0       0           0             0        0                 0   \n",
       "2             0       0           0             0        0                 0   \n",
       "3             0       0           0             0        0                 0   \n",
       "4             0       0           0             0        0                 0   \n",
       "...         ...     ...         ...           ...      ...               ...   \n",
       "4915          0       0           0             0        0                 0   \n",
       "4916          0       0           0             0        0                 0   \n",
       "4917          0       0           0             0        0                 0   \n",
       "4918          0       0           1             0        0                 0   \n",
       "4919          0       0           0             0        0                 0   \n",
       "\n",
       "      ...  blackheads  scurring  skin_peeling  silver_like_dusting  \\\n",
       "0     ...           0         0             0                    0   \n",
       "1     ...           0         0             0                    0   \n",
       "2     ...           0         0             0                    0   \n",
       "3     ...           0         0             0                    0   \n",
       "4     ...           0         0             0                    0   \n",
       "...   ...         ...       ...           ...                  ...   \n",
       "4915  ...           0         0             0                    0   \n",
       "4916  ...           1         1             0                    0   \n",
       "4917  ...           0         0             0                    0   \n",
       "4918  ...           0         0             1                    1   \n",
       "4919  ...           0         0             0                    0   \n",
       "\n",
       "      small_dents_in_nails  inflammatory_nails  blister  red_sore_around_nose  \\\n",
       "0                        0                   0        0                     0   \n",
       "1                        0                   0        0                     0   \n",
       "2                        0                   0        0                     0   \n",
       "3                        0                   0        0                     0   \n",
       "4                        0                   0        0                     0   \n",
       "...                    ...                 ...      ...                   ...   \n",
       "4915                     0                   0        0                     0   \n",
       "4916                     0                   0        0                     0   \n",
       "4917                     0                   0        0                     0   \n",
       "4918                     1                   1        0                     0   \n",
       "4919                     0                   0        1                     1   \n",
       "\n",
       "      yellow_crust_ooze                                prognosis  \n",
       "0                     0                         Fungal infection  \n",
       "1                     0                         Fungal infection  \n",
       "2                     0                         Fungal infection  \n",
       "3                     0                         Fungal infection  \n",
       "4                     0                         Fungal infection  \n",
       "...                 ...                                      ...  \n",
       "4915                  0  (vertigo) Paroymsal  Positional Vertigo  \n",
       "4916                  0                                     Acne  \n",
       "4917                  0                  Urinary tract infection  \n",
       "4918                  0                                Psoriasis  \n",
       "4919                  1                                 Impetigo  \n",
       "\n",
       "[4920 rows x 133 columns]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# vals = dataset.values.flatten()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(4920, 133)"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "train test split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import LabelEncoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = dataset.drop('prognosis', axis=1)\n",
    "y = dataset['prognosis']\n",
    "\n",
    "# ecoding prognonsis\n",
    "le = LabelEncoder()\n",
    "le.fit(y)\n",
    "Y = le.transform(y)\n",
    "    \n",
    "X_train, X_test, y_train, y_test = train_test_split(X, Y, test_size=0.3, random_state=20)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Training top models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SVC Accuracy: 1.0\n",
      "SVC Confusion Matrix:\n",
      "[[40,  0,  0, ...,  0,  0,  0],\n",
      " [ 0, 43,  0, ...,  0,  0,  0],\n",
      " [ 0,  0, 28, ...,  0,  0,  0],\n",
      " ...,\n",
      " [ 0,  0,  0, ..., 34,  0,  0],\n",
      " [ 0,  0,  0, ...,  0, 41,  0],\n",
      " [ 0,  0,  0, ...,  0,  0, 31]]\n",
      "\n",
      "========================================\n",
      "\n",
      "RandomForest Accuracy: 1.0\n",
      "RandomForest Confusion Matrix:\n",
      "[[40,  0,  0, ...,  0,  0,  0],\n",
      " [ 0, 43,  0, ...,  0,  0,  0],\n",
      " [ 0,  0, 28, ...,  0,  0,  0],\n",
      " ...,\n",
      " [ 0,  0,  0, ..., 34,  0,  0],\n",
      " [ 0,  0,  0, ...,  0, 41,  0],\n",
      " [ 0,  0,  0, ...,  0,  0, 31]]\n",
      "\n",
      "========================================\n",
      "\n",
      "GradientBoosting Accuracy: 1.0\n",
      "GradientBoosting Confusion Matrix:\n",
      "[[40,  0,  0, ...,  0,  0,  0],\n",
      " [ 0, 43,  0, ...,  0,  0,  0],\n",
      " [ 0,  0, 28, ...,  0,  0,  0],\n",
      " ...,\n",
      " [ 0,  0,  0, ..., 34,  0,  0],\n",
      " [ 0,  0,  0, ...,  0, 41,  0],\n",
      " [ 0,  0,  0, ...,  0,  0, 31]]\n",
      "\n",
      "========================================\n",
      "\n",
      "KNeighbors Accuracy: 1.0\n",
      "KNeighbors Confusion Matrix:\n",
      "[[40,  0,  0, ...,  0,  0,  0],\n",
      " [ 0, 43,  0, ...,  0,  0,  0],\n",
      " [ 0,  0, 28, ...,  0,  0,  0],\n",
      " ...,\n",
      " [ 0,  0,  0, ..., 34,  0,  0],\n",
      " [ 0,  0,  0, ...,  0, 41,  0],\n",
      " [ 0,  0,  0, ...,  0,  0, 31]]\n",
      "\n",
      "========================================\n",
      "\n",
      "MultinomialNB Accuracy: 1.0\n",
      "MultinomialNB Confusion Matrix:\n",
      "[[40,  0,  0, ...,  0,  0,  0],\n",
      " [ 0, 43,  0, ...,  0,  0,  0],\n",
      " [ 0,  0, 28, ...,  0,  0,  0],\n",
      " ...,\n",
      " [ 0,  0,  0, ..., 34,  0,  0],\n",
      " [ 0,  0,  0, ...,  0, 41,  0],\n",
      " [ 0,  0,  0, ...,  0,  0, 31]]\n",
      "\n",
      "========================================\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.datasets import make_classification\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.ensemble import RandomForestClassifier, GradientBoostingClassifier\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from sklearn.metrics import accuracy_score, confusion_matrix\n",
    "import numpy as np\n",
    "\n",
    "\n",
    "# Create a dictionary to store models\n",
    "models = {\n",
    "    'SVC': SVC(kernel='linear'),\n",
    "    'RandomForest': RandomForestClassifier(n_estimators=100, random_state=42),\n",
    "    'GradientBoosting': GradientBoostingClassifier(n_estimators=100, random_state=42),\n",
    "    'KNeighbors': KNeighborsClassifier(n_neighbors=5),\n",
    "    'MultinomialNB': MultinomialNB()\n",
    "}\n",
    "\n",
    "# Loop through the models, train, test, and print results\n",
    "for model_name, model in models.items():\n",
    "    # Train the model\n",
    "    model.fit(X_train, y_train)\n",
    "\n",
    "    # Test the model\n",
    "    predictions = model.predict(X_test)\n",
    "\n",
    "    # Calculate accuracy\n",
    "    accuracy = accuracy_score(y_test, predictions)\n",
    "    print(f\"{model_name} Accuracy: {accuracy}\")\n",
    "\n",
    "    # Calculate confusion matrix\n",
    "    cm = confusion_matrix(y_test, predictions)\n",
    "    print(f\"{model_name} Confusion Matrix:\")\n",
    "    print(np.array2string(cm, separator=', '))\n",
    "\n",
    "    print(\"\\n\" + \"=\"*40 + \"\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1.0"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "# selecting svc\n",
    "svc = SVC(kernel='linear')\n",
    "svc.fit(X_train,y_train)\n",
    "ypred = svc.predict(X_test)\n",
    "accuracy_score(y_test,ypred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# save svc\n",
    "import pickle\n",
    "pickle.dump(svc,open('svc.pkl','wb'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load model\n",
    "svc = pickle.load(open('svc.pkl','rb'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "predicted disease : [40]\n",
      "Actual Disease : 40\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\rajpr\\anaconda3\\Lib\\site-packages\\sklearn\\utils\\validation.py:2739: UserWarning: X does not have valid feature names, but SVC was fitted with feature names\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "# test 1:\n",
    "print(\"predicted disease :\",svc.predict(X_test.iloc[0].values.reshape(1,-1)))\n",
    "print(\"Actual Disease :\", y_test[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "predicted disease : [39]\n",
      "Actual Disease : 39\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\rajpr\\anaconda3\\Lib\\site-packages\\sklearn\\utils\\validation.py:2739: UserWarning: X does not have valid feature names, but SVC was fitted with feature names\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "# test 2:\n",
    "print(\"predicted disease :\",svc.predict(X_test.iloc[100].values.reshape(1,-1)))\n",
    "print(\"Actual Disease :\", y_test[100])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Recommendation System and Prediction"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "load database and use logic for recommendations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "sym_des = pd.read_csv(\"symtoms_df.csv\")\n",
    "precautions = pd.read_csv(\"precautions_df.csv\")\n",
    "workout = pd.read_csv(\"workout_df.csv\")\n",
    "description = pd.read_csv(\"description.csv\")\n",
    "medications = pd.read_csv('medications.csv')\n",
    "diets = pd.read_csv(\"diets.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "#============================================================\n",
    "# custome and helping functions\n",
    "#==========================helper funtions================\n",
    "def helper(dis):\n",
    "    desc = description[description['Disease'] == predicted_disease]['Description']\n",
    "    desc = \" \".join([w for w in desc])\n",
    "\n",
    "    pre = precautions[precautions['Disease'] == dis][['Precaution_1', 'Precaution_2', 'Precaution_3', 'Precaution_4']]\n",
    "    pre = [col for col in pre.values]\n",
    "\n",
    "    med = medications[medications['Disease'] == dis]['Medication']\n",
    "    med = [med for med in med.values]\n",
    "\n",
    "    die = diets[diets['Disease'] == dis]['Diet']\n",
    "    die = [die for die in die.values]\n",
    "\n",
    "    wrkout = workout[workout['disease'] == dis] ['workout']\n",
    "\n",
    "\n",
    "    return desc,pre,med,die,wrkout\n",
    "\n",
    "symptoms_dict = {'itching': 0, 'skin_rash': 1, 'nodal_skin_eruptions': 2, 'continuous_sneezing': 3, 'shivering': 4, 'chills': 5, 'joint_pain': 6, 'stomach_pain': 7, 'acidity': 8, 'ulcers_on_tongue': 9, 'muscle_wasting': 10, 'vomiting': 11, 'burning_micturition': 12, 'spotting_ urination': 13, 'fatigue': 14, 'weight_gain': 15, 'anxiety': 16, 'cold_hands_and_feets': 17, 'mood_swings': 18, 'weight_loss': 19, 'restlessness': 20, 'lethargy': 21, 'patches_in_throat': 22, 'irregular_sugar_level': 23, 'cough': 24, 'high_fever': 25, 'sunken_eyes': 26, 'breathlessness': 27, 'sweating': 28, 'dehydration': 29, 'indigestion': 30, 'headache': 31, 'yellowish_skin': 32, 'dark_urine': 33, 'nausea': 34, 'loss_of_appetite': 35, 'pain_behind_the_eyes': 36, 'back_pain': 37, 'constipation': 38, 'abdominal_pain': 39, 'diarrhoea': 40, 'mild_fever': 41, 'yellow_urine': 42, 'yellowing_of_eyes': 43, 'acute_liver_failure': 44, 'fluid_overload': 45, 'swelling_of_stomach': 46, 'swelled_lymph_nodes': 47, 'malaise': 48, 'blurred_and_distorted_vision': 49, 'phlegm': 50, 'throat_irritation': 51, 'redness_of_eyes': 52, 'sinus_pressure': 53, 'runny_nose': 54, 'congestion': 55, 'chest_pain': 56, 'weakness_in_limbs': 57, 'fast_heart_rate': 58, 'pain_during_bowel_movements': 59, 'pain_in_anal_region': 60, 'bloody_stool': 61, 'irritation_in_anus': 62, 'neck_pain': 63, 'dizziness': 64, 'cramps': 65, 'bruising': 66, 'obesity': 67, 'swollen_legs': 68, 'swollen_blood_vessels': 69, 'puffy_face_and_eyes': 70, 'enlarged_thyroid': 71, 'brittle_nails': 72, 'swollen_extremeties': 73, 'excessive_hunger': 74, 'extra_marital_contacts': 75, 'drying_and_tingling_lips': 76, 'slurred_speech': 77, 'knee_pain': 78, 'hip_joint_pain': 79, 'muscle_weakness': 80, 'stiff_neck': 81, 'swelling_joints': 82, 'movement_stiffness': 83, 'spinning_movements': 84, 'loss_of_balance': 85, 'unsteadiness': 86, 'weakness_of_one_body_side': 87, 'loss_of_smell': 88, 'bladder_discomfort': 89, 'foul_smell_of urine': 90, 'continuous_feel_of_urine': 91, 'passage_of_gases': 92, 'internal_itching': 93, 'toxic_look_(typhos)': 94, 'depression': 95, 'irritability': 96, 'muscle_pain': 97, 'altered_sensorium': 98, 'red_spots_over_body': 99, 'belly_pain': 100, 'abnormal_menstruation': 101, 'dischromic _patches': 102, 'watering_from_eyes': 103, 'increased_appetite': 104, 'polyuria': 105, 'family_history': 106, 'mucoid_sputum': 107, 'rusty_sputum': 108, 'lack_of_concentration': 109, 'visual_disturbances': 110, 'receiving_blood_transfusion': 111, 'receiving_unsterile_injections': 112, 'coma': 113, 'stomach_bleeding': 114, 'distention_of_abdomen': 115, 'history_of_alcohol_consumption': 116, 'fluid_overload.1': 117, 'blood_in_sputum': 118, 'prominent_veins_on_calf': 119, 'palpitations': 120, 'painful_walking': 121, 'pus_filled_pimples': 122, 'blackheads': 123, 'scurring': 124, 'skin_peeling': 125, 'silver_like_dusting': 126, 'small_dents_in_nails': 127, 'inflammatory_nails': 128, 'blister': 129, 'red_sore_around_nose': 130, 'yellow_crust_ooze': 131}\n",
    "diseases_list = {15: 'Fungal infection', 4: 'Allergy', 16: 'GERD', 9: 'Chronic cholestasis', 14: 'Drug Reaction', 33: 'Peptic ulcer diseae', 1: 'AIDS', 12: 'Diabetes ', 17: 'Gastroenteritis', 6: 'Bronchial Asthma', 23: 'Hypertension ', 30: 'Migraine', 7: 'Cervical spondylosis', 32: 'Paralysis (brain hemorrhage)', 28: 'Jaundice', 29: 'Malaria', 8: 'Chicken pox', 11: 'Dengue', 37: 'Typhoid', 40: 'hepatitis A', 19: 'Hepatitis B', 20: 'Hepatitis C', 21: 'Hepatitis D', 22: 'Hepatitis E', 3: 'Alcoholic hepatitis', 36: 'Tuberculosis', 10: 'Common Cold', 34: 'Pneumonia', 13: 'Dimorphic hemmorhoids(piles)', 18: 'Heart attack', 39: 'Varicose veins', 26: 'Hypothyroidism', 24: 'Hyperthyroidism', 25: 'Hypoglycemia', 31: 'Osteoarthristis', 5: 'Arthritis', 0: '(vertigo) Paroymsal  Positional Vertigo', 2: 'Acne', 38: 'Urinary tract infection', 35: 'Psoriasis', 27: 'Impetigo'}\n",
    "\n",
    "# Model Prediction function\n",
    "def get_predicted_value(patient_symptoms):\n",
    "    input_vector = np.zeros(len(symptoms_dict))\n",
    "    for item in patient_symptoms:\n",
    "        input_vector[symptoms_dict[item]] = 1\n",
    "    return diseases_list[svc.predict([input_vector])[0]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=================predicted disease============\n",
      "Fungal infection\n",
      "=================description==================\n",
      "Fungal infection is a common skin condition caused by fungi.\n",
      "=================precautions==================\n",
      "1 :  bath twice\n",
      "2 :  use detol or neem in bathing water\n",
      "3 :  keep infected area dry\n",
      "4 :  use clean cloths\n",
      "=================medications==================\n",
      "5 :  ['Antifungal Cream', 'Fluconazole', 'Terbinafine', 'Clotrimazole', 'Ketoconazole']\n",
      "=================workout==================\n",
      "6 :  Avoid sugary foods\n",
      "7 :  Consume probiotics\n",
      "8 :  Increase intake of garlic\n",
      "9 :  Include yogurt in diet\n",
      "10 :  Limit processed foods\n",
      "11 :  Stay hydrated\n",
      "12 :  Consume green tea\n",
      "13 :  Eat foods rich in zinc\n",
      "14 :  Include turmeric in diet\n",
      "15 :  Eat fruits and vegetables\n",
      "=================diets==================\n",
      "16 :  ['Antifungal Diet', 'Probiotics', 'Garlic', 'Coconut oil', 'Turmeric']\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\rajpr\\anaconda3\\Lib\\site-packages\\sklearn\\utils\\validation.py:2739: UserWarning: X does not have valid feature names, but SVC was fitted with feature names\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "# Test 1\n",
    "# Split the user's input into a list of symptoms (assuming they are comma-separated) # itching,skin_rash,nodal_skin_eruptions\n",
    "symptoms = input(\"Enter your symptoms.......\")\n",
    "user_symptoms = [s.strip() for s in symptoms.split(',')]\n",
    "# Remove any extra characters, if any\n",
    "user_symptoms = [symptom.strip(\"[]' \") for symptom in user_symptoms]\n",
    "predicted_disease = get_predicted_value(user_symptoms)\n",
    "\n",
    "desc, pre, med, die, wrkout = helper(predicted_disease)\n",
    "\n",
    "print(\"=================predicted disease============\")\n",
    "print(predicted_disease)\n",
    "print(\"=================description==================\")\n",
    "print(desc)\n",
    "print(\"=================precautions==================\")\n",
    "i = 1\n",
    "for p_i in pre[0]:\n",
    "    print(i, \": \", p_i)\n",
    "    i += 1\n",
    "\n",
    "print(\"=================medications==================\")\n",
    "for m_i in med:\n",
    "    print(i, \": \", m_i)\n",
    "    i += 1\n",
    "\n",
    "print(\"=================workout==================\")\n",
    "for w_i in wrkout:\n",
    "    print(i, \": \", w_i)\n",
    "    i += 1\n",
    "\n",
    "print(\"=================diets==================\")\n",
    "for d_i in die:\n",
    "    print(i, \": \", d_i)\n",
    "    i += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['.env', '.venv', 'dataset', 'main.py', 'Medicine Recommendation System.ipynb', 'models', 'personalized_medication_dataset.csv', 'static', 'templates', 'train_model.py']\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "print(os.listdir())  # Shows files in current directory"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model Accuracy: 0.00%\n"
     ]
    }
   ],
   "source": [
    "import pickle\n",
    "import pandas as pd\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "# 1. Load the trained model\n",
    "try:\n",
    "    with open(r'C:\\Users\\rajpr\\OneDrive\\Desktop\\test\\models\\svc.pkl', 'rb') as file:\n",
    "        svc = pickle.load(file)\n",
    "except FileNotFoundError:\n",
    "    print(\"Error: svc.pkl file not found. Please ensure:\")\n",
    "    print(\"- The file exists in your current directory\")\n",
    "    print(\"- Or provide the full path to the file\")\n",
    "    raise\n",
    "\n",
    "# 2. Load and prepare data\n",
    "try:\n",
    "    dataset = pd.read_csv(r'C:\\Users\\rajpr\\OneDrive\\Desktop\\test\\dataset\\Training.csv')\n",
    "    X = dataset.drop('prognosis', axis=1)\n",
    "    y = dataset['prognosis']\n",
    "    \n",
    "    # Train-test split (use same random_state as during training)\n",
    "    X_train, X_test, y_train, y_test = train_test_split(\n",
    "        X, y, test_size=0.3, random_state=20)\n",
    "except FileNotFoundError:\n",
    "    print(\"Error: Training.csv file not found\")\n",
    "    raise\n",
    "\n",
    "# 3. Calculate and print accuracy\n",
    "y_pred = svc.predict(X_test)\n",
    "accuracy = accuracy_score(y_test, y_pred)\n",
    "print(f\"Model Accuracy: {accuracy * 100:.2f}%\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model Accuracy: 0.00%\n"
     ]
    }
   ],
   "source": [
    "import pickle\n",
    "import pandas as pd\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.model_selection import train_test_split  # You were missing this import\n",
    "\n",
    "# 1. Load the trained model\n",
    "try:\n",
    "    with open('C:\\\\Users\\\\rajpr\\\\OneDrive\\\\Desktop\\\\test\\models\\\\svc.pkl', 'rb') as file:\n",
    "        svc = pickle.load(file)\n",
    "except FileNotFoundError:\n",
    "    print(\"Error: svc.pkl file not found. Please ensure:\")\n",
    "    print(\"- The file exists at the specified path\")\n",
    "    print(\"- The path is correct (check for typos)\")\n",
    "    raise\n",
    "\n",
    "# 2. Load and prepare data\n",
    "try:\n",
    "    dataset = pd.read_csv('C:\\\\Users\\\\rajpr\\\\OneDrive\\\\Desktop\\\\test\\\\dataset\\\\Training.csv')\n",
    "    X = dataset.drop('prognosis', axis=1)\n",
    "    y = dataset['prognosis']\n",
    "    \n",
    "    # Train-test split (use same random_state as during training)\n",
    "    X_train, X_test, y_train, y_test = train_test_split(\n",
    "        X, y, test_size=0.3, random_state=20)\n",
    "except FileNotFoundError:\n",
    "    print(\"Error: Training.csv file not found at specified path\")\n",
    "    raise\n",
    "except Exception as e:\n",
    "    print(f\"Error loading data: {str(e)}\")\n",
    "    raise\n",
    "\n",
    "# 3. Calculate and print accuracy\n",
    "try:\n",
    "    y_pred = svc.predict(X_test)\n",
    "    accuracy = accuracy_score(y_test, y_pred)\n",
    "    print(f\"Model Accuracy: {accuracy * 100:.2f}%\")\n",
    "except Exception as e:\n",
    "    print(f\"Error during prediction: {str(e)}\")\n",
    "    raise"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shape of dataset: (1000, 17)\n",
      "\n",
      "Column names: ['Patient_ID', 'Age', 'Gender', 'Weight_kg', 'Height_cm', 'BMI', 'Chronic_Conditions', 'Drug_Allergies', 'Genetic_Disorders', 'Diagnosis', 'Symptoms', 'Recommended_Medication', 'Dosage', 'Duration', 'Treatment_Effectiveness', 'Adverse_Reactions', 'Recovery_Time_Days']\n",
      "\n",
      "Data types:\n",
      " Patient_ID                  object\n",
      "Age                          int64\n",
      "Gender                      object\n",
      "Weight_kg                  float64\n",
      "Height_cm                  float64\n",
      "BMI                        float64\n",
      "Chronic_Conditions          object\n",
      "Drug_Allergies              object\n",
      "Genetic_Disorders           object\n",
      "Diagnosis                   object\n",
      "Symptoms                    object\n",
      "Recommended_Medication      object\n",
      "Dosage                      object\n",
      "Duration                    object\n",
      "Treatment_Effectiveness     object\n",
      "Adverse_Reactions           object\n",
      "Recovery_Time_Days           int64\n",
      "dtype: object\n",
      "\n",
      "First 5 rows:\n",
      "  Patient_ID  Age  Gender  Weight_kg  Height_cm   BMI Chronic_Conditions  \\\n",
      "0      P0001   78   Other       88.7      196.3  21.1                NaN   \n",
      "1      P0002   57  Female       90.5      195.6  30.2       Hypertension   \n",
      "2      P0003   29  Female       87.0      168.2  27.0                NaN   \n",
      "3      P0004   56  Female       81.4      188.9  26.9       Hypertension   \n",
      "4      P0005   90    Male       64.2      157.0  33.3                NaN   \n",
      "\n",
      "  Drug_Allergies   Genetic_Disorders     Diagnosis  \\\n",
      "0     Penicillin     Cystic Fibrosis  Inflammation   \n",
      "1            NaN     Cystic Fibrosis    Depression   \n",
      "2          Sulfa                 NaN  Inflammation   \n",
      "3     Penicillin     Cystic Fibrosis     Infection   \n",
      "4          Sulfa  Sickle Cell Anemia  Inflammation   \n",
      "\n",
      "                       Symptoms Recommended_Medication  Dosage Duration  \\\n",
      "0                         Fever             Amlodipine     NaN  30 days   \n",
      "1  Fatigue, Headache, Dizziness            Amoxicillin    5 mg      NaN   \n",
      "2  Joint Pain, Headache, Nausea                    NaN     NaN   7 days   \n",
      "3                    Joint Pain              Ibuprofen  200 mg   7 days   \n",
      "4      Fatigue, Fever, Headache             Amlodipine  500 mg  10 days   \n",
      "\n",
      "  Treatment_Effectiveness Adverse_Reactions  Recovery_Time_Days  \n",
      "0               Effective               Yes                  18  \n",
      "1                 Neutral                No                  24  \n",
      "2               Effective               Yes                  12  \n",
      "3          Very Effective                No                  22  \n",
      "4             Ineffective               Yes                  25  \n",
      "Numerical Columns: ['Age', 'Weight_kg', 'Height_cm', 'BMI', 'Recovery_Time_Days']\n",
      "Categorical Columns: ['Patient_ID', 'Gender', 'Chronic_Conditions', 'Drug_Allergies', 'Genetic_Disorders', 'Diagnosis', 'Symptoms', 'Recommended_Medication', 'Dosage', 'Duration', 'Treatment_Effectiveness', 'Adverse_Reactions']\n",
      "\n",
      "Missing values after imputation:\n",
      " Patient_ID                 0\n",
      "Age                        0\n",
      "Gender                     0\n",
      "Weight_kg                  0\n",
      "Height_cm                  0\n",
      "BMI                        0\n",
      "Chronic_Conditions         0\n",
      "Drug_Allergies             0\n",
      "Genetic_Disorders          0\n",
      "Diagnosis                  0\n",
      "Symptoms                   0\n",
      "Recommended_Medication     0\n",
      "Dosage                     0\n",
      "Duration                   0\n",
      "Treatment_Effectiveness    0\n",
      "Adverse_Reactions          0\n",
      "Recovery_Time_Days         0\n",
      "dtype: int64\n"
     ]
    }
   ],
   "source": [
    "# Step 1: Load and inspect the dataset\n",
    "\n",
    "import pandas as pd\n",
    "\n",
    "# Load the dataset\n",
    "file_path = 'datasets/personalized_medication_dataset.csv'  # update if path is different\n",
    "df = pd.read_csv(file_path)\n",
    "\n",
    "# Basic info about the dataset\n",
    "print(\"Shape of dataset:\", df.shape)\n",
    "print(\"\\nColumn names:\", df.columns.tolist())\n",
    "print(\"\\nData types:\\n\", df.dtypes)\n",
    "print(\"\\nFirst 5 rows:\")\n",
    "print(df.head())\n",
    "\n",
    "\n",
    "from sklearn.impute import SimpleImputer\n",
    "import numpy as np\n",
    "\n",
    "# Separate numerical and categorical columns\n",
    "num_cols = df.select_dtypes(include=['int64', 'float64']).columns.tolist()\n",
    "cat_cols = df.select_dtypes(include=['object']).columns.tolist()\n",
    "\n",
    "print(\"Numerical Columns:\", num_cols)\n",
    "print(\"Categorical Columns:\", cat_cols)\n",
    "\n",
    "# Imputation strategies\n",
    "num_imputer = SimpleImputer(strategy='mean')\n",
    "cat_imputer = SimpleImputer(strategy='most_frequent')\n",
    "\n",
    "# Apply imputations\n",
    "df[num_cols] = num_imputer.fit_transform(df[num_cols])\n",
    "df[cat_cols] = cat_imputer.fit_transform(df[cat_cols])\n",
    "\n",
    "# Final check for missing values\n",
    "print(\"\\nMissing values after imputation:\\n\", df.isnull().sum())\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âœ… Feature Processing Done\n",
      "X_train_processed shape: (800, 228)\n",
      "Target columns: ['Recommended_Medication', 'Dosage', 'Duration']\n"
     ]
    }
   ],
   "source": [
    "from sklearn.preprocessing import StandardScaler, OneHotEncoder\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# Define target and features\n",
    "target_cols = ['Recommended_Medication', 'Dosage', 'Duration']\n",
    "\n",
    "# Remove target columns to get X\n",
    "X = df.drop(columns=target_cols)\n",
    "\n",
    "# Remove 'Patient_ID' if still exists\n",
    "if 'Patient_ID' in X.columns:\n",
    "    X = X.drop(columns=['Patient_ID'])\n",
    "\n",
    "y = df[target_cols]\n",
    "\n",
    "# Separate column types\n",
    "numerical_cols = X.select_dtypes(include=['int64', 'float64']).columns.tolist()\n",
    "categorical_cols = X.select_dtypes(include=['object']).columns.tolist()\n",
    "\n",
    "# Define preprocessing pipeline\n",
    "preprocessor = ColumnTransformer(\n",
    "    transformers=[\n",
    "        ('num', StandardScaler(), numerical_cols),\n",
    "        ('cat', OneHotEncoder(handle_unknown='ignore'), categorical_cols)\n",
    "    ])\n",
    "\n",
    "# Split data\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "# Apply preprocessing\n",
    "X_train_processed = preprocessor.fit_transform(X_train)\n",
    "X_test_processed = preprocessor.transform(X_test)\n",
    "\n",
    "print(\"âœ… Feature Processing Done\")\n",
    "print(\"X_train_processed shape:\", X_train_processed.shape)\n",
    "print(\"Target columns:\", y.columns.tolist())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âœ… Feature Engineering Done!\n",
      "    Age Age_Group Immunity_Level Treatment_Cost_Type Urgency_Level\n",
      "0  78.0    Senior            Low             Branded           Low\n",
      "1  57.0     Adult            Low             Branded           Low\n",
      "2  29.0     Adult            Low             Branded           Low\n",
      "3  56.0     Adult            Low             Branded           Low\n",
      "4  90.0    Senior            Low             Branded           Low\n"
     ]
    }
   ],
   "source": [
    "def age_group(age):\n",
    "    if age < 18:\n",
    "        return 'Child'\n",
    "    elif age < 60:\n",
    "        return 'Adult'\n",
    "    else:\n",
    "        return 'Senior'\n",
    "\n",
    "def immunity_level(bmi, chronic, genetic):\n",
    "    score = 0\n",
    "    if bmi < 18.5 or bmi > 30:\n",
    "        score += 1\n",
    "    if chronic != 'None':\n",
    "        score += 1\n",
    "    if genetic != 'None':\n",
    "        score += 1\n",
    "    if score == 0:\n",
    "        return 'High'\n",
    "    elif score == 1:\n",
    "        return 'Medium'\n",
    "    else:\n",
    "        return 'Low'\n",
    "\n",
    "def treatment_cost_type(med_name):\n",
    "    if 'generic' in med_name.lower():\n",
    "        return 'Generic'\n",
    "    else:\n",
    "        return 'Branded'\n",
    "\n",
    "def urgency_level(days):\n",
    "    if days <= 3:\n",
    "        return 'High'\n",
    "    elif days <= 7:\n",
    "        return 'Moderate'\n",
    "    else:\n",
    "        return 'Low'\n",
    "\n",
    "# Apply feature engineering\n",
    "df['Age_Group'] = df['Age'].apply(age_group)\n",
    "df['Immunity_Level'] = df.apply(lambda row: immunity_level(row['BMI'], row['Chronic_Conditions'], row['Genetic_Disorders']), axis=1)\n",
    "df['Treatment_Cost_Type'] = df['Recommended_Medication'].apply(treatment_cost_type)\n",
    "df['Urgency_Level'] = df['Recovery_Time_Days'].apply(urgency_level)\n",
    "\n",
    "# Show new columns\n",
    "print(\"âœ… Feature Engineering Done!\")\n",
    "print(df[['Age', 'Age_Group', 'Immunity_Level', 'Treatment_Cost_Type', 'Urgency_Level']].head())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 139,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âœ… Step 5: Personalization Model Trained Successfully!\n"
     ]
    }
   ],
   "source": [
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "from sklearn.multioutput import MultiOutputClassifier\n",
    "\n",
    "# Step 5.1: Create new personalization input features\n",
    "personalization_features = ['Age_Group', 'Immunity_Level', 'Treatment_Cost_Type', 'Urgency_Level']\n",
    "X_personal = df[personalization_features]\n",
    "\n",
    "# Step 5.2: Define target\n",
    "Y_personal = df[['Recommended_Medication', 'Dosage', 'Duration']]\n",
    "\n",
    "# Encode target using LabelEncoder (multi-label)\n",
    "target_encoders = {}\n",
    "Y_encoded = pd.DataFrame()\n",
    "\n",
    "for col in Y_personal.columns:\n",
    "    le = LabelEncoder()\n",
    "    Y_encoded[col] = le.fit_transform(Y_personal[col])\n",
    "    target_encoders[col] = le  # Save encoder for decoding later\n",
    "\n",
    "# Step 5.3: Encode categorical inputs (OneHot)\n",
    "# Step 5.3: Encode categorical inputs (OneHot) â€” with unknowns allowed\n",
    "preprocessor = ColumnTransformer(\n",
    "    transformers=[\n",
    "        ('cat', OneHotEncoder(handle_unknown='ignore'), personalization_features)\n",
    "    ]\n",
    ")\n",
    "\n",
    "# Step 5.4: Train a lightweight multi-output model\n",
    "model = Pipeline(steps=[\n",
    "    ('preprocessor', preprocessor),\n",
    "    ('classifier', MultiOutputClassifier(RandomForestClassifier(random_state=42)))\n",
    "])\n",
    "\n",
    "model.fit(X_personal, Y_encoded)\n",
    "\n",
    "print(\"âœ… Step 5: Personalization Model Trained Successfully!\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 140,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'Medication': 'Amoxicillin', 'Dosage': '5 mg', 'Duration': '7 days'}"
      ]
     },
     "execution_count": 140,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "get_personalized_recommendation(\n",
    "    age=45,\n",
    "    bmi=22.5,\n",
    "    chronic_conditions='None',\n",
    "    base_medication='MedB',\n",
    "    base_dosage='500mg',\n",
    "    base_duration='5 days',\n",
    "    recovery_days=6\n",
    ")\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Test\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 141,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "ðŸ“Œ Accuracy for 'Recommended_Medication':\n",
      "Accuracy: 0.465\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.00      0.00      0.00        52\n",
      "           1       0.47      0.99      0.63        94\n",
      "           2       0.00      0.00      0.00        54\n",
      "\n",
      "    accuracy                           0.47       200\n",
      "   macro avg       0.16      0.33      0.21       200\n",
      "weighted avg       0.22      0.47      0.30       200\n",
      "\n",
      "\n",
      "ðŸ“Œ Accuracy for 'Dosage':\n",
      "Accuracy: 0.455\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.00      0.00      0.00        43\n",
      "           1       0.00      0.00      0.00        31\n",
      "           2       0.46      1.00      0.63        91\n",
      "           3       0.00      0.00      0.00        35\n",
      "\n",
      "    accuracy                           0.46       200\n",
      "   macro avg       0.11      0.25      0.16       200\n",
      "weighted avg       0.21      0.46      0.28       200\n",
      "\n",
      "\n",
      "ðŸ“Œ Accuracy for 'Duration':\n",
      "Accuracy: 0.57\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.00      0.00      0.00        37\n",
      "           1       0.00      0.00      0.00        49\n",
      "           2       0.57      1.00      0.73       114\n",
      "\n",
      "    accuracy                           0.57       200\n",
      "   macro avg       0.19      0.33      0.24       200\n",
      "weighted avg       0.32      0.57      0.41       200\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import accuracy_score, classification_report\n",
    "\n",
    "# Step 1: Split the personalization dataset\n",
    "X_train_p, X_test_p, y_train_p, y_test_p = train_test_split(\n",
    "    X_personal, Y_encoded, test_size=0.2, random_state=42\n",
    ")\n",
    "\n",
    "# Step 2: Retrain the model on training data\n",
    "model.fit(X_train_p, y_train_p)\n",
    "\n",
    "# Step 3: Predict on test data\n",
    "y_pred_p = model.predict(X_test_p)\n",
    "\n",
    "# Step 4: Evaluate each target column separately\n",
    "for idx, column in enumerate(Y_encoded.columns):\n",
    "    print(f\"\\nðŸ“Œ Accuracy for '{column}':\")\n",
    "    print(\"Accuracy:\", accuracy_score(y_test_p[column], y_pred_p[:, idx]))\n",
    "    print(classification_report(y_test_p[column], y_pred_p[:, idx]))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 186,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X_train shape: (1240, 4)\n",
      "y_train shape: (1240, 3)\n"
     ]
    }
   ],
   "source": [
    "print(\"X_train shape:\", X_train.shape)\n",
    "print(\"y_train shape:\", y_train.shape)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 189,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X_train type: <class 'pandas.core.frame.DataFrame'>\n",
      "X_train shape: (1240, 4)\n",
      "y_train type: <class 'pandas.core.frame.DataFrame'>\n",
      "y_train shape: (1240, 3)\n",
      "First few rows of y_train:       Dosage  Duration  Recommended_Medication\n",
      "1231       3         2                       0\n",
      "788        3         2                       2\n",
      "1251       1         2                       0\n",
      "381        2         0                       1\n",
      "1348       0         1                       2\n"
     ]
    }
   ],
   "source": [
    "print(\"X_train type:\", type(X_train))\n",
    "print(\"X_train shape:\", X_train.shape)\n",
    "\n",
    "print(\"y_train type:\", type(y_train))\n",
    "print(\"y_train shape:\", y_train.shape)\n",
    "\n",
    "print(\"First few rows of y_train:\", y_train[:5])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 193,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "dataset = pd.read_csv(\"datasets/Training.csv\")  # Make sure the path is correct\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 195,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Index(['itching', 'skin_rash', 'nodal_skin_eruptions', 'continuous_sneezing',\n",
      "       'shivering', 'chills', 'joint_pain', 'stomach_pain', 'acidity',\n",
      "       'ulcers_on_tongue',\n",
      "       ...\n",
      "       'blackheads', 'scurring', 'skin_peeling', 'silver_like_dusting',\n",
      "       'small_dents_in_nails', 'inflammatory_nails', 'blister',\n",
      "       'red_sore_around_nose', 'yellow_crust_ooze', 'prognosis'],\n",
      "      dtype='object', length=133)\n"
     ]
    }
   ],
   "source": [
    "print(dataset.columns)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 197,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SVC Accuracy: 1.0000\n",
      "RandomForest Accuracy: 1.0000\n",
      "GradientBoosting Accuracy: 1.0000\n",
      "KNeighbors Accuracy: 1.0000\n",
      "MultinomialNB Accuracy: 1.0000\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.ensemble import RandomForestClassifier, GradientBoostingClassifier\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "# Load the dataset\n",
    "dataset = pd.read_csv(\"datasets/Training.csv\")\n",
    "\n",
    "# Separate features and target\n",
    "X = dataset.drop('prognosis', axis=1)\n",
    "y = dataset['prognosis']\n",
    "\n",
    "# Encode target labels\n",
    "le = LabelEncoder()\n",
    "y_encoded = le.fit_transform(y)\n",
    "\n",
    "# Train-test split\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y_encoded, test_size=0.3, random_state=42)\n",
    "\n",
    "# Define models\n",
    "models = {\n",
    "    'SVC': SVC(kernel='linear'),\n",
    "    'RandomForest': RandomForestClassifier(n_estimators=100, random_state=42),\n",
    "    'GradientBoosting': GradientBoostingClassifier(n_estimators=100, random_state=42),\n",
    "    'KNeighbors': KNeighborsClassifier(n_neighbors=5),\n",
    "    'MultinomialNB': MultinomialNB()\n",
    "}\n",
    "\n",
    "# Train and evaluate each model\n",
    "for model_name, model in models.items():\n",
    "    model.fit(X_train, y_train)\n",
    "    predictions = model.predict(X_test)\n",
    "    accuracy = accuracy_score(y_test, predictions)\n",
    "    print(f\"{model_name} Accuracy: {accuracy:.4f}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 198,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SVC Accuracy on full dataset: 1.0000\n",
      "RandomForest Accuracy on full dataset: 1.0000\n",
      "GradientBoosting Accuracy on full dataset: 1.0000\n",
      "KNeighbors Accuracy on full dataset: 1.0000\n",
      "MultinomialNB Accuracy on full dataset: 1.0000\n"
     ]
    }
   ],
   "source": [
    "# Use full dataset for training and testing\n",
    "X = dataset.drop('prognosis', axis=1)\n",
    "y = dataset['prognosis']\n",
    "\n",
    "# Encode labels\n",
    "le = LabelEncoder()\n",
    "y_encoded = le.fit_transform(y)\n",
    "\n",
    "# Train and test on the same data\n",
    "for model_name, model in models.items():\n",
    "    model.fit(X, y_encoded)\n",
    "    predictions = model.predict(X)\n",
    "    accuracy = accuracy_score(y_encoded, predictions)\n",
    "    print(f\"{model_name} Accuracy on full dataset: {accuracy:.4f}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 201,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SVC Accuracy on full data: 1.0000\n",
      "RandomForest Accuracy on full data: 1.0000\n",
      "GradientBoosting Accuracy on full data: 1.0000\n",
      "KNeighbors Accuracy on full data: 1.0000\n",
      "MultinomialNB Accuracy on full data: 1.0000\n"
     ]
    }
   ],
   "source": [
    "# Full dataset\n",
    "X_full = dataset.drop('prognosis', axis=1)\n",
    "y_full = le.fit_transform(dataset['prognosis'])\n",
    "\n",
    "# Train and test on the full data\n",
    "for model_name, model in models.items():\n",
    "    model.fit(X_full, y_full)\n",
    "    predictions = model.predict(X_full)\n",
    "    accuracy = accuracy_score(y_full, predictions)\n",
    "    print(f\"{model_name} Accuracy on full data: {accuracy:.4f}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 202,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Cross-validation results:\n",
      "SVC CV Accuracy: 1.0000 Â± 0.0000\n",
      "RandomForest CV Accuracy: 1.0000 Â± 0.0000\n",
      "GradientBoosting CV Accuracy: 1.0000 Â± 0.0000\n",
      "KNeighbors CV Accuracy: 1.0000 Â± 0.0000\n",
      "MultinomialNB CV Accuracy: 1.0000 Â± 0.0000\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import cross_val_score\n",
    "\n",
    "print(\"\\nCross-validation results:\")\n",
    "for model_name, model in models.items():\n",
    "    scores = cross_val_score(model, X_full, y_full, cv=5)\n",
    "    print(f\"{model_name} CV Accuracy: {scores.mean():.4f} Â± {scores.std():.4f}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 203,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model Accuracy: 100.00%\n"
     ]
    }
   ],
   "source": [
    "print(f\"Model Accuracy: {accuracy * 100:.2f}%\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âœ… Saved model: medication_model.pkl\n",
      "âœ… Saved model: dosage_model.pkl\n",
      "âœ… Saved model: duration_model.pkl\n",
      "âœ… Saved model: effectiveness_model.pkl\n",
      "âœ… Saved model: reactions_model.pkl\n",
      "âœ… Saved model: recovery_model.pkl\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import joblib\n",
    "import os\n",
    "from sklearn.ensemble import RandomForestClassifier, RandomForestRegressor\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.preprocessing import OneHotEncoder, StandardScaler\n",
    "from sklearn.impute import SimpleImputer\n",
    "\n",
    "# Step 1: Load the dataset\n",
    "df = pd.read_csv(\"dataset/personalized_medication_dataset.csv\")\n",
    "\n",
    "# Step 2: Drop unnecessary columns\n",
    "df.drop(columns=['Patient_ID', 'BMI'], inplace=True)\n",
    "\n",
    "# Step 3: Define input features and targets\n",
    "features = ['Age', 'Gender', 'Weight_kg', 'Height_cm', 'Chronic_Conditions',\n",
    "            'Drug_Allergies', 'Genetic_Disorders', 'Diagnosis', 'Symptoms']\n",
    "\n",
    "targets = {\n",
    "    'medication_model.pkl': ('Recommended_Medication', RandomForestClassifier()),\n",
    "    'dosage_model.pkl': ('Dosage', RandomForestClassifier()),\n",
    "    'duration_model.pkl': ('Duration', RandomForestClassifier()),\n",
    "    'effectiveness_model.pkl': ('Treatment_Effectiveness', RandomForestClassifier()),\n",
    "    'reactions_model.pkl': ('Adverse_Reactions', RandomForestClassifier()),\n",
    "    'recovery_model.pkl': ('Recovery_Time_Days', RandomForestRegressor()),\n",
    "}\n",
    "\n",
    "# Step 4: Define preprocessing steps\n",
    "numeric_features = ['Age', 'Weight_kg', 'Height_cm']\n",
    "categorical_features = ['Gender', 'Chronic_Conditions', 'Drug_Allergies', 'Genetic_Disorders', 'Diagnosis', 'Symptoms']\n",
    "\n",
    "numeric_transformer = Pipeline(steps=[\n",
    "    ('imputer', SimpleImputer(strategy='mean')),\n",
    "    ('scaler', StandardScaler())\n",
    "])\n",
    "\n",
    "categorical_transformer = Pipeline(steps=[\n",
    "    ('imputer', SimpleImputer(strategy='constant', fill_value='missing')),\n",
    "    ('onehot', OneHotEncoder(handle_unknown='ignore'))\n",
    "])\n",
    "\n",
    "preprocessor = ColumnTransformer(\n",
    "    transformers=[\n",
    "        ('num', numeric_transformer, numeric_features),\n",
    "        ('cat', categorical_transformer, categorical_features)\n",
    "    ])\n",
    "\n",
    "# Step 5: Make sure model directory exists\n",
    "os.makedirs('models', exist_ok=True)\n",
    "\n",
    "# Step 6: Train and save each model\n",
    "for filename, (target_col, model) in targets.items():\n",
    "    df_target = df.dropna(subset=[target_col])  # drop rows where target is missing\n",
    "    X = df_target[features]\n",
    "    y = df_target[target_col]\n",
    "\n",
    "    clf = Pipeline(steps=[\n",
    "        ('preprocessor', preprocessor),\n",
    "        ('model', model)\n",
    "    ])\n",
    "\n",
    "    clf.fit(X, y)\n",
    "    joblib.dump(clf, f'models/{filename}')\n",
    "    print(f\"âœ… Saved model: {filename}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.6.1\n"
     ]
    }
   ],
   "source": [
    "# let's use pycharm flask app\n",
    "# but install this version in pycharm\n",
    "import sklearn\n",
    "print(sklearn.__version__)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
